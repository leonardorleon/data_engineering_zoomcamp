{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f557b3-c31c-48fb-b2c2-fde5589f913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5cefa7-089d-42be-aa47-60614ff12fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/02 16:01:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('test')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03acd6f-22e9-498d-996d-06324a07b9f0",
   "metadata": {},
   "source": [
    "For this session, we would like to replicate this query we've done in previous parts through the usage of rdds:\n",
    "\n",
    "SELECT\n",
    "    date_trunc(\"hour\", lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS zone,\n",
    "     \n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "\n",
    "FROM \n",
    "    green\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY \n",
    "    1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc1124a-dfa8-4947-9d39-e42fe4f746ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# let's start by reading the green taxi dataset\n",
    "\n",
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64850412-2a7f-4afa-8f83-c86a5d5a1a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 13, 38, 16), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=130, passenger_count=1, trip_distance=12.77, fare_amount=36.0, extra=0.0, mta_tax=0.5, tip_amount=2.05, tolls_amount=6.12, ehail_fee=None, improvement_surcharge=0.3, total_amount=44.97, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), lpep_dropoff_datetime=datetime.datetime(2020, 1, 20, 15, 46), store_and_fwd_flag=None, RatecodeID=None, PULocationID=67, DOLocationID=39, passenger_count=None, trip_distance=8.0, fare_amount=29.9, extra=2.75, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=33.45, payment_type=None, trip_type=None, congestion_surcharge=None),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 20, 31, 18), store_and_fwd_flag='N', RatecodeID=1, PULocationID=260, DOLocationID=157, passenger_count=1, trip_distance=1.27, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), lpep_dropoff_datetime=datetime.datetime(2020, 1, 5, 16, 40, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=82, DOLocationID=83, passenger_count=1, trip_distance=1.25, fare_amount=7.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 19, 31, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=42, passenger_count=1, trip_distance=1.84, fare_amount=8.0, extra=1.0, mta_tax=0.5, tip_amount=2.94, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.74, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 11, 7, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 11, 11, 31), store_and_fwd_flag='N', RatecodeID=1, PULocationID=179, DOLocationID=223, passenger_count=2, trip_distance=0.76, fare_amount=5.0, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=5.8, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 16, 8, 22, 29), lpep_dropoff_datetime=datetime.datetime(2020, 1, 16, 8, 50, 24), store_and_fwd_flag='N', RatecodeID=1, PULocationID=41, DOLocationID=237, passenger_count=1, trip_distance=3.32, fare_amount=18.5, extra=0.0, mta_tax=0.5, tip_amount=3.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=25.05, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 28, 17, 5, 28), lpep_dropoff_datetime=datetime.datetime(2020, 1, 28, 17, 26, 11), store_and_fwd_flag='N', RatecodeID=1, PULocationID=75, DOLocationID=161, passenger_count=1, trip_distance=2.21, fare_amount=14.0, extra=1.0, mta_tax=0.5, tip_amount=2.78, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=21.33, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=1, lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 14, 51, 37), lpep_dropoff_datetime=datetime.datetime(2020, 1, 22, 14, 57, 29), store_and_fwd_flag='N', RatecodeID=1, PULocationID=152, DOLocationID=166, passenger_count=1, trip_distance=0.9, fare_amount=6.0, extra=0.0, mta_tax=0.5, tip_amount=1.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=7.8, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 10, 25, 4), lpep_dropoff_datetime=datetime.datetime(2020, 1, 31, 10, 52, 13), store_and_fwd_flag='N', RatecodeID=1, PULocationID=75, DOLocationID=234, passenger_count=1, trip_distance=6.1, fare_amount=22.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=26.05, payment_type=2, trip_type=1, congestion_surcharge=2.75)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inside the dataframe, there is a field called rdd, which is the internal underline rdd\n",
    "df_green.rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e7e133-f465-46fc-a3f3-4c7588c7a9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 13, 38, 16), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=130, passenger_count=1, trip_distance=12.77, fare_amount=36.0, extra=0.0, mta_tax=0.5, tip_amount=2.05, tolls_amount=6.12, ehail_fee=None, improvement_surcharge=0.3, total_amount=44.97, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), lpep_dropoff_datetime=datetime.datetime(2020, 1, 20, 15, 46), store_and_fwd_flag=None, RatecodeID=None, PULocationID=67, DOLocationID=39, passenger_count=None, trip_distance=8.0, fare_amount=29.9, extra=2.75, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=33.45, payment_type=None, trip_type=None, congestion_surcharge=None),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 20, 31, 18), store_and_fwd_flag='N', RatecodeID=1, PULocationID=260, DOLocationID=157, passenger_count=1, trip_distance=1.27, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), lpep_dropoff_datetime=datetime.datetime(2020, 1, 5, 16, 40, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=82, DOLocationID=83, passenger_count=1, trip_distance=1.25, fare_amount=7.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 19, 31, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=42, passenger_count=1, trip_distance=1.84, fare_amount=8.0, extra=1.0, mta_tax=0.5, tip_amount=2.94, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.74, payment_type=1, trip_type=1, congestion_surcharge=0.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502d9e66-d235-412f-9e8d-4e4c32281dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only keep the columns that we are interested in\n",
    "\n",
    "rdd = df_green\\\n",
    "            .select('lpep_pickup_datetime','PULocationID','total_amount')\\\n",
    "            .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5954ead-91dc-4747-81d4-85f316f0b071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07703bca-20d8-420f-af4b-c95422ec3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = rdd.take(10)\n",
    "row = rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b777dbc8-b886-49d7-a94c-0a31a280a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.97"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6044136a-9aa1-4fdd-814b-28d8aedae6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first thing we can do is filter the data, implement the where statement from the query\n",
    "\n",
    "start = datetime(year=2020,month=1, day=1)\n",
    "\n",
    "# create a function to serve as a filter for the data, replicating the where condition\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46e4fad9-fd32-4f53-bee6-984096f4e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also create a function to transform the data so that it conforms to the map transformation.\n",
    "# In order to do a groupby, we need to prepare the data to a key,value format\n",
    "def prepare_for_grouping(row):\n",
    "    # prepare the key portion of our data\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    # prepare the value portion of our data\n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81b9605-543b-464d-9510-c2e36ffb92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's work on the reduce function, which needs to go by parts, so it'll take first two values from the same key and reduce them to one\n",
    "# then it will continue with that reduced key value pair and perform the same operation with the next record sharing the same key. This same process will\n",
    "# continue until it finishes.\n",
    "\n",
    "def calculate_revenue(left_value, right_value):\n",
    "    # first unpack the tuples for each set of values\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "\n",
    "    # Let's perform the operations we need, in this case calculate the amount and the count\n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "\n",
    "    # return the tuple with the results, which will be attached to the key    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0121c2-ea35-4c98-8d22-e7d2f0c8d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally, the reduce by key function would return a key, value structure for each row. They'd look like this:\n",
    "[((datetime.datetime(2020, 1, 15, 20, 0), 260), (163.90000000000003, 14)),\n",
    " ((datetime.datetime(2020, 1, 29, 19, 0), 166), (695.0099999999999, 45)),\n",
    " ((datetime.datetime(2020, 1, 16, 8, 0), 41), (736.1399999999996, 54)),\n",
    " ((datetime.datetime(2020, 1, 4, 20, 0), 129), (583.27, 38)),\n",
    " ((datetime.datetime(2020, 1, 2, 8, 0), 66), (197.69, 10)),\n",
    " ((datetime.datetime(2020, 1, 3, 9, 0), 61), (142.21, 9)),\n",
    " ((datetime.datetime(2020, 1, 17, 21, 0), 236), (33.6, 4)),\n",
    " ((datetime.datetime(2020, 1, 12, 12, 0), 82), (290.41, 14)),\n",
    " ((datetime.datetime(2020, 1, 28, 16, 0), 197), (831.4399999999998, 18)),\n",
    " ((datetime.datetime(2020, 1, 10, 22, 0), 95), (407.7100000000002, 37))]\n",
    "\n",
    " where each key is a tuple and each value is also a tuple of aggregated values. But this is not very manageable, so let's \n",
    " turn it once again into a dataframe by unwrapping it.\n",
    "'''\n",
    "\n",
    "def unwrap(row):\n",
    "    return (row[0][0], row[0][1], row[1][0], row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c3ccbb9-28a1-4ae1-9679-de76e0cbd9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---+\n",
      "|                 _1| _2|                _3| _4|\n",
      "+-------------------+---+------------------+---+\n",
      "|2020-01-15 20:00:00|260|163.90000000000003| 14|\n",
      "|2020-01-29 19:00:00|166| 695.0099999999999| 45|\n",
      "|2020-01-16 08:00:00| 41| 736.1399999999996| 54|\n",
      "|2020-01-04 20:00:00|129|            583.27| 38|\n",
      "|2020-01-02 08:00:00| 66|            197.69| 10|\n",
      "|2020-01-03 09:00:00| 61|            142.21|  9|\n",
      "|2020-01-17 21:00:00|236|              33.6|  4|\n",
      "|2020-01-12 12:00:00| 82|            290.41| 14|\n",
      "|2020-01-28 16:00:00|197| 831.4399999999998| 18|\n",
      "|2020-01-10 22:00:00| 95| 407.7100000000002| 37|\n",
      "|2020-01-10 01:00:00|215|            109.69|  2|\n",
      "|2020-01-07 18:00:00| 25| 554.2900000000001| 37|\n",
      "|2020-01-18 07:00:00| 55|              48.3|  1|\n",
      "|2020-01-28 09:00:00|166| 473.0200000000002| 36|\n",
      "|2020-01-12 15:00:00| 82| 265.7900000000001| 29|\n",
      "|2020-01-10 20:00:00| 66|            405.88| 21|\n",
      "|2020-01-31 15:00:00| 43|345.58000000000004| 19|\n",
      "|2020-01-31 21:00:00| 41| 588.1600000000001| 40|\n",
      "|2020-01-25 18:00:00| 65| 457.0600000000001| 28|\n",
      "|2020-01-26 14:00:00|166| 301.7900000000001| 26|\n",
      "+-------------------+---+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ebf8d4-8f4b-478d-ac18-92fda74e8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main issue with this solution right now, is that the column names are lost, including the schema. So this can be solved the following wya\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9e6b617-dc5a-4192-a4f1-c354a82cf693",
   "metadata": {},
   "outputs": [],
   "source": [
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "306d8d21-3658-46c8-adbd-ffb0ca484b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "            hour = row[0][0],\n",
    "            zone = row[0][1], \n",
    "            revenue = row[1][0], \n",
    "            count = row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b4dd06e-8432-4a61-af7c-921e2afc3e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-15 20:00:00| 260|163.90000000000003|   14|\n",
      "|2020-01-29 19:00:00| 166| 695.0099999999999|   45|\n",
      "|2020-01-16 08:00:00|  41| 736.1399999999996|   54|\n",
      "|2020-01-04 20:00:00| 129|            583.27|   38|\n",
      "|2020-01-02 08:00:00|  66|            197.69|   10|\n",
      "|2020-01-03 09:00:00|  61|            142.21|    9|\n",
      "|2020-01-17 21:00:00| 236|              33.6|    4|\n",
      "|2020-01-12 12:00:00|  82|            290.41|   14|\n",
      "|2020-01-28 16:00:00| 197| 831.4399999999998|   18|\n",
      "|2020-01-10 22:00:00|  95| 407.7100000000002|   37|\n",
      "|2020-01-10 01:00:00| 215|            109.69|    2|\n",
      "|2020-01-07 18:00:00|  25| 554.2900000000001|   37|\n",
      "|2020-01-18 07:00:00|  55|              48.3|    1|\n",
      "|2020-01-28 09:00:00| 166| 473.0200000000002|   36|\n",
      "|2020-01-12 15:00:00|  82| 265.7900000000001|   29|\n",
      "|2020-01-10 20:00:00|  66|            405.88|   21|\n",
      "|2020-01-31 15:00:00|  43|345.58000000000004|   19|\n",
      "|2020-01-31 21:00:00|  41| 588.1600000000001|   40|\n",
      "|2020-01-25 18:00:00|  65| 457.0600000000001|   28|\n",
      "|2020-01-26 14:00:00| 166| 301.7900000000001|   26|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f77fe95-8962-4d0a-baf5-50824b90b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12e4c624-69ad-4e4d-92c0-55daadc55af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hour', TimestampType(), True), StructField('zone', LongType(), True), StructField('revenue', DoubleType(), True), StructField('count', LongType(), True)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that the schema is not really there, so let's modify it manually in vscode\n",
    "df_result.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0595e9fd-667c-4047-91cd-426010260d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f545ceae-c7e4-4b90-83d6-329805c225da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b95c9013-6005-442d-884c-7d8d8260d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aac768a-6f59-418f-813c-b828c25dde56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hour', TimestampType(), True), StructField('zone', IntegerType(), True), StructField('revenue', DoubleType(), True), StructField('count', IntegerType(), True)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79dea792-f1f8-4413-920b-5f1c77bf3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-15 20:00:00| 260|163.90000000000003|   14|\n",
      "|2020-01-29 19:00:00| 166| 695.0099999999999|   45|\n",
      "|2020-01-16 08:00:00|  41| 736.1399999999996|   54|\n",
      "|2020-01-04 20:00:00| 129|            583.27|   38|\n",
      "|2020-01-02 08:00:00|  66|            197.69|   10|\n",
      "|2020-01-03 09:00:00|  61|            142.21|    9|\n",
      "|2020-01-17 21:00:00| 236|              33.6|    4|\n",
      "|2020-01-12 12:00:00|  82|            290.41|   14|\n",
      "|2020-01-28 16:00:00| 197| 831.4399999999998|   18|\n",
      "|2020-01-10 22:00:00|  95| 407.7100000000002|   37|\n",
      "|2020-01-10 01:00:00| 215|            109.69|    2|\n",
      "|2020-01-07 18:00:00|  25| 554.2900000000001|   37|\n",
      "|2020-01-18 07:00:00|  55|              48.3|    1|\n",
      "|2020-01-28 09:00:00| 166| 473.0200000000002|   36|\n",
      "|2020-01-12 15:00:00|  82| 265.7900000000001|   29|\n",
      "|2020-01-10 20:00:00|  66|            405.88|   21|\n",
      "|2020-01-31 15:00:00|  43|345.58000000000004|   19|\n",
      "|2020-01-31 21:00:00|  41| 588.1600000000001|   40|\n",
      "|2020-01-25 18:00:00|  65| 457.0600000000001|   28|\n",
      "|2020-01-26 14:00:00| 166| 301.7900000000001|   26|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6bb5a59-616d-498f-9e23-01249d0c4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# let's save it to see the full execution DAG \n",
    "\n",
    "df_result.write.parquet('data/tmp/green-revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5657a31e-d6fb-4d31-9929-1bead9c58113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmapPartition\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mapPartition\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d541ad1-ce45-4fef-8307-2aaeb940355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID','lpep_pickup_datetime','PULocationID','DOLocationID','trip_distance']\n",
    "\n",
    "duration_rdd = df_green \\\n",
    "                .select(columns) \\\n",
    "                .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765e88b6-8c9b-4f3c-be52-f44fa5dd374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, DOLocationID=130, trip_distance=12.77),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, DOLocationID=39, trip_distance=8.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, DOLocationID=157, trip_distance=1.27),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, DOLocationID=83, trip_distance=1.25),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, DOLocationID=42, trip_distance=1.84)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e1c93b-a5c6-49e7-a80f-be76c89c3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b00835d-a47d-4242-bff7-8ad7f6987695",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = duration_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e0ed8a-3ef8-40e2-94ad-6be541f179bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-23 13:10:15</td>\n",
       "      <td>74</td>\n",
       "      <td>130</td>\n",
       "      <td>12.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-20 15:09:00</td>\n",
       "      <td>67</td>\n",
       "      <td>39</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-15 20:23:41</td>\n",
       "      <td>260</td>\n",
       "      <td>157</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-05 16:32:26</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-29 19:22:42</td>\n",
       "      <td>166</td>\n",
       "      <td>42</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-15 11:07:42</td>\n",
       "      <td>179</td>\n",
       "      <td>223</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-16 08:22:29</td>\n",
       "      <td>41</td>\n",
       "      <td>237</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-28 17:05:28</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-22 14:51:37</td>\n",
       "      <td>152</td>\n",
       "      <td>166</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-31 10:25:04</td>\n",
       "      <td>75</td>\n",
       "      <td>234</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime  PULocationID  DOLocationID  trip_distance\n",
       "0       2.0  2020-01-23 13:10:15            74           130          12.77\n",
       "1       NaN  2020-01-20 15:09:00            67            39           8.00\n",
       "2       2.0  2020-01-15 20:23:41           260           157           1.27\n",
       "3       2.0  2020-01-05 16:32:26            82            83           1.25\n",
       "4       2.0  2020-01-29 19:22:42           166            42           1.84\n",
       "5       2.0  2020-01-15 11:07:42           179           223           0.76\n",
       "6       2.0  2020-01-16 08:22:29            41           237           3.32\n",
       "7       2.0  2020-01-28 17:05:28            75           161           2.21\n",
       "8       1.0  2020-01-22 14:51:37           152           166           0.90\n",
       "9       2.0  2020-01-31 10:25:04            75           234           6.10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80fc87d4-781c-4f67-a9b3-fe8e9b026366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ...\n",
    "\n",
    "def model_predict(df):\n",
    "    # y_pred = model.predict(df)  \n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54785e23-4950-4c55-8bda-187b1b9c020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_in_batch(rows):\n",
    "\n",
    "    df = pd.DataFrame(rows,columns=columns)\n",
    "\n",
    "    df['lpep_pickup_datetime'] = df['lpep_pickup_datetime'].astype(str) # string conversion so spark can understand the dates\n",
    "    \n",
    "    predictions = model_predict(df)\n",
    "    df['predicted_duration'] = predictions\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5afdeef-a386-4ad1-b23c-9fcbd9f1216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|Index|VendorID|lpep_pickup_datetime|PULocationID|DOLocationID|trip_distance|predicted_duration|\n",
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|    0|     2.0| 2020-01-23 13:10:15|          74|         130|        12.77|63.849999999999994|\n",
      "|    1|     NaN| 2020-01-20 15:09:00|          67|          39|          8.0|              40.0|\n",
      "|    2|     2.0| 2020-01-15 20:23:41|         260|         157|         1.27|              6.35|\n",
      "|    3|     2.0| 2020-01-05 16:32:26|          82|          83|         1.25|              6.25|\n",
      "|    4|     2.0| 2020-01-29 19:22:42|         166|          42|         1.84| 9.200000000000001|\n",
      "|    5|     2.0| 2020-01-15 11:07:42|         179|         223|         0.76|               3.8|\n",
      "|    6|     2.0| 2020-01-16 08:22:29|          41|         237|         3.32|16.599999999999998|\n",
      "|    7|     2.0| 2020-01-28 17:05:28|          75|         161|         2.21|             11.05|\n",
      "|    8|     1.0| 2020-01-22 14:51:37|         152|         166|          0.9|               4.5|\n",
      "|    9|     2.0| 2020-01-31 10:25:04|          75|         234|          6.1|              30.5|\n",
      "|   10|     2.0| 2020-01-20 15:50:54|          75|          41|         1.74|               8.7|\n",
      "|   11|     2.0| 2020-01-31 11:35:17|         260|         226|         1.18|5.8999999999999995|\n",
      "|   12|     1.0| 2020-01-04 20:44:28|         129|         129|          2.2|              11.0|\n",
      "|   13|     2.0| 2020-01-17 21:47:52|          74|         126|         3.04|              15.2|\n",
      "|   14|     2.0| 2020-01-21 23:13:47|          61|          61|         0.85|              4.25|\n",
      "|   15|     2.0| 2020-01-02 08:11:21|          66|         164|         5.06|25.299999999999997|\n",
      "|   16|     2.0| 2020-01-27 02:59:20|           7|         179|         1.57|7.8500000000000005|\n",
      "|   17|     2.0| 2020-01-16 14:39:13|          74|         243|          6.8|              34.0|\n",
      "|   18|     2.0| 2020-01-16 18:42:24|          66|          97|         1.06| 5.300000000000001|\n",
      "|   19|     2.0| 2020-01-03 09:24:54|          61|         225|         1.23|              6.15|\n",
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75791e-4426-4077-9337-2eed2c4df4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
