{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f557b3-c31c-48fb-b2c2-fde5589f913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5cefa7-089d-42be-aa47-60614ff12fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/02 11:45:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('test')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03acd6f-22e9-498d-996d-06324a07b9f0",
   "metadata": {},
   "source": [
    "For this session, we would like to replicate this query we've done in previous parts through the usage of rdds:\n",
    "\n",
    "SELECT\n",
    "    date_trunc(\"hour\", lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS zone,\n",
    "     \n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "\n",
    "FROM \n",
    "    green\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY \n",
    "    1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc1124a-dfa8-4947-9d39-e42fe4f746ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# let's start by reading the green taxi dataset\n",
    "\n",
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64850412-2a7f-4afa-8f83-c86a5d5a1a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 13, 38, 16), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=130, passenger_count=1, trip_distance=12.77, fare_amount=36.0, extra=0.0, mta_tax=0.5, tip_amount=2.05, tolls_amount=6.12, ehail_fee=None, improvement_surcharge=0.3, total_amount=44.97, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), lpep_dropoff_datetime=datetime.datetime(2020, 1, 20, 15, 46), store_and_fwd_flag=None, RatecodeID=None, PULocationID=67, DOLocationID=39, passenger_count=None, trip_distance=8.0, fare_amount=29.9, extra=2.75, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=33.45, payment_type=None, trip_type=None, congestion_surcharge=None),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 20, 31, 18), store_and_fwd_flag='N', RatecodeID=1, PULocationID=260, DOLocationID=157, passenger_count=1, trip_distance=1.27, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), lpep_dropoff_datetime=datetime.datetime(2020, 1, 5, 16, 40, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=82, DOLocationID=83, passenger_count=1, trip_distance=1.25, fare_amount=7.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 19, 31, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=42, passenger_count=1, trip_distance=1.84, fare_amount=8.0, extra=1.0, mta_tax=0.5, tip_amount=2.94, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.74, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 11, 7, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 11, 11, 31), store_and_fwd_flag='N', RatecodeID=1, PULocationID=179, DOLocationID=223, passenger_count=2, trip_distance=0.76, fare_amount=5.0, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=5.8, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 16, 8, 22, 29), lpep_dropoff_datetime=datetime.datetime(2020, 1, 16, 8, 50, 24), store_and_fwd_flag='N', RatecodeID=1, PULocationID=41, DOLocationID=237, passenger_count=1, trip_distance=3.32, fare_amount=18.5, extra=0.0, mta_tax=0.5, tip_amount=3.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=25.05, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 28, 17, 5, 28), lpep_dropoff_datetime=datetime.datetime(2020, 1, 28, 17, 26, 11), store_and_fwd_flag='N', RatecodeID=1, PULocationID=75, DOLocationID=161, passenger_count=1, trip_distance=2.21, fare_amount=14.0, extra=1.0, mta_tax=0.5, tip_amount=2.78, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=21.33, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=1, lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 14, 51, 37), lpep_dropoff_datetime=datetime.datetime(2020, 1, 22, 14, 57, 29), store_and_fwd_flag='N', RatecodeID=1, PULocationID=152, DOLocationID=166, passenger_count=1, trip_distance=0.9, fare_amount=6.0, extra=0.0, mta_tax=0.5, tip_amount=1.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=7.8, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 10, 25, 4), lpep_dropoff_datetime=datetime.datetime(2020, 1, 31, 10, 52, 13), store_and_fwd_flag='N', RatecodeID=1, PULocationID=75, DOLocationID=234, passenger_count=1, trip_distance=6.1, fare_amount=22.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=26.05, payment_type=2, trip_type=1, congestion_surcharge=2.75)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inside the dataframe, there is a field called rdd, which is the internal underline rdd\n",
    "df_green.rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e7e133-f465-46fc-a3f3-4c7588c7a9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 13, 38, 16), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=130, passenger_count=1, trip_distance=12.77, fare_amount=36.0, extra=0.0, mta_tax=0.5, tip_amount=2.05, tolls_amount=6.12, ehail_fee=None, improvement_surcharge=0.3, total_amount=44.97, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), lpep_dropoff_datetime=datetime.datetime(2020, 1, 20, 15, 46), store_and_fwd_flag=None, RatecodeID=None, PULocationID=67, DOLocationID=39, passenger_count=None, trip_distance=8.0, fare_amount=29.9, extra=2.75, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=33.45, payment_type=None, trip_type=None, congestion_surcharge=None),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 20, 31, 18), store_and_fwd_flag='N', RatecodeID=1, PULocationID=260, DOLocationID=157, passenger_count=1, trip_distance=1.27, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), lpep_dropoff_datetime=datetime.datetime(2020, 1, 5, 16, 40, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=82, DOLocationID=83, passenger_count=1, trip_distance=1.25, fare_amount=7.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 19, 31, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=42, passenger_count=1, trip_distance=1.84, fare_amount=8.0, extra=1.0, mta_tax=0.5, tip_amount=2.94, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.74, payment_type=1, trip_type=1, congestion_surcharge=0.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502d9e66-d235-412f-9e8d-4e4c32281dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only keep the columns that we are interested in\n",
    "\n",
    "rdd = df_green\\\n",
    "            .select('lpep_pickup_datetime','PULocationID','total_amount')\\\n",
    "            .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5954ead-91dc-4747-81d4-85f316f0b071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07703bca-20d8-420f-af4b-c95422ec3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = rdd.take(10)\n",
    "row = rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b777dbc8-b886-49d7-a94c-0a31a280a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.97"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6044136a-9aa1-4fdd-814b-28d8aedae6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first thing we can do is filter the data, implement the where statement from the query\n",
    "\n",
    "start = datetime(year=2020,month=1, day=1)\n",
    "\n",
    "# create a function to serve as a filter for the data, replicating the where condition\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46e4fad9-fd32-4f53-bee6-984096f4e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also create a function to transform the data so that it conforms to the map transformation.\n",
    "# In order to do a groupby, we need to prepare the data to a key,value format\n",
    "def prepare_for_grouping(row):\n",
    "    # prepare the key portion of our data\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    # prepare the value portion of our data\n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81b9605-543b-464d-9510-c2e36ffb92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's work on the reduce function, which needs to go by parts, so it'll take first two values from the same key and reduce them to one\n",
    "# then it will continue with that reduced key value pair and perform the same operation with the next record sharing the same key. This same process will\n",
    "# continue until it finishes.\n",
    "\n",
    "def calculate_revenue(left_value, right_value):\n",
    "    # first unpack the tuples for each set of values\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "\n",
    "    # Let's perform the operations we need, in this case calculate the amount and the count\n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "\n",
    "    # return the tuple with the results, which will be attached to the key    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0121c2-ea35-4c98-8d22-e7d2f0c8d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally, the reduce by key function would return a key, value structure for each row. They'd look like this:\n",
    "[((datetime.datetime(2020, 1, 15, 20, 0), 260), (163.90000000000003, 14)),\n",
    " ((datetime.datetime(2020, 1, 29, 19, 0), 166), (695.0099999999999, 45)),\n",
    " ((datetime.datetime(2020, 1, 16, 8, 0), 41), (736.1399999999996, 54)),\n",
    " ((datetime.datetime(2020, 1, 4, 20, 0), 129), (583.27, 38)),\n",
    " ((datetime.datetime(2020, 1, 2, 8, 0), 66), (197.69, 10)),\n",
    " ((datetime.datetime(2020, 1, 3, 9, 0), 61), (142.21, 9)),\n",
    " ((datetime.datetime(2020, 1, 17, 21, 0), 236), (33.6, 4)),\n",
    " ((datetime.datetime(2020, 1, 12, 12, 0), 82), (290.41, 14)),\n",
    " ((datetime.datetime(2020, 1, 28, 16, 0), 197), (831.4399999999998, 18)),\n",
    " ((datetime.datetime(2020, 1, 10, 22, 0), 95), (407.7100000000002, 37))]\n",
    "\n",
    " where each key is a tuple and each value is also a tuple of aggregated values. But this is not very manageable, so let's \n",
    " turn it once again into a dataframe by unwrapping it.\n",
    "'''\n",
    "\n",
    "def unwrap(row):\n",
    "    return (row[0][0], row[0][1], row[1][0], row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c3ccbb9-28a1-4ae1-9679-de76e0cbd9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---+\n",
      "|                 _1| _2|                _3| _4|\n",
      "+-------------------+---+------------------+---+\n",
      "|2020-01-15 20:00:00|260|163.90000000000003| 14|\n",
      "|2020-01-29 19:00:00|166| 695.0099999999999| 45|\n",
      "|2020-01-16 08:00:00| 41| 736.1399999999996| 54|\n",
      "|2020-01-04 20:00:00|129|            583.27| 38|\n",
      "|2020-01-02 08:00:00| 66|            197.69| 10|\n",
      "|2020-01-03 09:00:00| 61|            142.21|  9|\n",
      "|2020-01-17 21:00:00|236|              33.6|  4|\n",
      "|2020-01-12 12:00:00| 82|            290.41| 14|\n",
      "|2020-01-28 16:00:00|197| 831.4399999999998| 18|\n",
      "|2020-01-10 22:00:00| 95| 407.7100000000002| 37|\n",
      "|2020-01-10 01:00:00|215|            109.69|  2|\n",
      "|2020-01-07 18:00:00| 25| 554.2900000000001| 37|\n",
      "|2020-01-18 07:00:00| 55|              48.3|  1|\n",
      "|2020-01-28 09:00:00|166| 473.0200000000002| 36|\n",
      "|2020-01-12 15:00:00| 82| 265.7900000000001| 29|\n",
      "|2020-01-10 20:00:00| 66|            405.88| 21|\n",
      "|2020-01-31 15:00:00| 43|345.58000000000004| 19|\n",
      "|2020-01-31 21:00:00| 41| 588.1600000000001| 40|\n",
      "|2020-01-25 18:00:00| 65| 457.0600000000001| 28|\n",
      "|2020-01-26 14:00:00|166| 301.7900000000001| 26|\n",
      "+-------------------+---+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ebf8d4-8f4b-478d-ac18-92fda74e8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main issue with this solution right now, is that the column names are lost, including the schema. So this can be solved the following wya\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9e6b617-dc5a-4192-a4f1-c354a82cf693",
   "metadata": {},
   "outputs": [],
   "source": [
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "306d8d21-3658-46c8-adbd-ffb0ca484b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "            hour = row[0][0],\n",
    "            zone = row[0][1], \n",
    "            revenue = row[1][0], \n",
    "            count = row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b4dd06e-8432-4a61-af7c-921e2afc3e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-15 20:00:00| 260|163.90000000000003|   14|\n",
      "|2020-01-29 19:00:00| 166| 695.0099999999999|   45|\n",
      "|2020-01-16 08:00:00|  41| 736.1399999999996|   54|\n",
      "|2020-01-04 20:00:00| 129|            583.27|   38|\n",
      "|2020-01-02 08:00:00|  66|            197.69|   10|\n",
      "|2020-01-03 09:00:00|  61|            142.21|    9|\n",
      "|2020-01-17 21:00:00| 236|              33.6|    4|\n",
      "|2020-01-12 12:00:00|  82|            290.41|   14|\n",
      "|2020-01-28 16:00:00| 197| 831.4399999999998|   18|\n",
      "|2020-01-10 22:00:00|  95| 407.7100000000002|   37|\n",
      "|2020-01-10 01:00:00| 215|            109.69|    2|\n",
      "|2020-01-07 18:00:00|  25| 554.2900000000001|   37|\n",
      "|2020-01-18 07:00:00|  55|              48.3|    1|\n",
      "|2020-01-28 09:00:00| 166| 473.0200000000002|   36|\n",
      "|2020-01-12 15:00:00|  82| 265.7900000000001|   29|\n",
      "|2020-01-10 20:00:00|  66|            405.88|   21|\n",
      "|2020-01-31 15:00:00|  43|345.58000000000004|   19|\n",
      "|2020-01-31 21:00:00|  41| 588.1600000000001|   40|\n",
      "|2020-01-25 18:00:00|  65| 457.0600000000001|   28|\n",
      "|2020-01-26 14:00:00| 166| 301.7900000000001|   26|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f77fe95-8962-4d0a-baf5-50824b90b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12e4c624-69ad-4e4d-92c0-55daadc55af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hour', TimestampType(), True), StructField('zone', LongType(), True), StructField('revenue', DoubleType(), True), StructField('count', LongType(), True)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that the schema is not really there, so let's modify it manually in vscode\n",
    "df_result.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0595e9fd-667c-4047-91cd-426010260d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f545ceae-c7e4-4b90-83d6-329805c225da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b95c9013-6005-442d-884c-7d8d8260d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aac768a-6f59-418f-813c-b828c25dde56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hour', TimestampType(), True), StructField('zone', IntegerType(), True), StructField('revenue', DoubleType(), True), StructField('count', IntegerType(), True)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79dea792-f1f8-4413-920b-5f1c77bf3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-15 20:00:00| 260|163.90000000000003|   14|\n",
      "|2020-01-29 19:00:00| 166| 695.0099999999999|   45|\n",
      "|2020-01-16 08:00:00|  41| 736.1399999999996|   54|\n",
      "|2020-01-04 20:00:00| 129|            583.27|   38|\n",
      "|2020-01-02 08:00:00|  66|            197.69|   10|\n",
      "|2020-01-03 09:00:00|  61|            142.21|    9|\n",
      "|2020-01-17 21:00:00| 236|              33.6|    4|\n",
      "|2020-01-12 12:00:00|  82|            290.41|   14|\n",
      "|2020-01-28 16:00:00| 197| 831.4399999999998|   18|\n",
      "|2020-01-10 22:00:00|  95| 407.7100000000002|   37|\n",
      "|2020-01-10 01:00:00| 215|            109.69|    2|\n",
      "|2020-01-07 18:00:00|  25| 554.2900000000001|   37|\n",
      "|2020-01-18 07:00:00|  55|              48.3|    1|\n",
      "|2020-01-28 09:00:00| 166| 473.0200000000002|   36|\n",
      "|2020-01-12 15:00:00|  82| 265.7900000000001|   29|\n",
      "|2020-01-10 20:00:00|  66|            405.88|   21|\n",
      "|2020-01-31 15:00:00|  43|345.58000000000004|   19|\n",
      "|2020-01-31 21:00:00|  41| 588.1600000000001|   40|\n",
      "|2020-01-25 18:00:00|  65| 457.0600000000001|   28|\n",
      "|2020-01-26 14:00:00| 166| 301.7900000000001|   26|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6bb5a59-616d-498f-9e23-01249d0c4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# let's save it to see the full execution DAG \n",
    "\n",
    "df_result.write.parquet('data/tmp/green-revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657a31e-d6fb-4d31-9929-1bead9c58113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
